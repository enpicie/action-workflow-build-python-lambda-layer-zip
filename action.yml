name: 'Build Lambda Layer Zip and Upload to S3'
description: 'Installs dependencies from requirements.txt, zips for Lambda Layer, and uploads to S3 if requirements changed.'

inputs:
  requirements_path:
    description: 'Path to requirements.txt file'
    required: true
  app_name:
    description: 'Name of application (used in .zip name)'
    required: true
  python_runtime:
    description: 'Python runtime version Layers are built for (e.g., 3.11)'
    required: true
  s3_layer_bucket_name:
    description: 'Name of the S3 bucket to upload the ZIP file to'
    required: false
    default: 'lambda.layer.python3'
  aws_region:
    description: 'AWS region for S3 bucket'
    required: false
    default: 'us-east-2'
  aws_role_arn:
    description: 'ARN of AWS IAM role to assume for S3 access'
    required: true

outputs:
  zip_file_name:
    description: 'Final ZIP file name including .zip extension'
    value: ${{ steps.set-zip-and-s3.outputs.zip_file_name }}
  s3_artifact_key:
    description: 'Full S3 key for the uploaded ZIP artifact'
    value: ${{ steps.set-zip-and-s3.outputs.s3_artifact_key }}

runs:
  using: 'composite'
  steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Configure AWS credentials (OIDC + role assumption)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ inputs.aws_role_arn }}
        aws-region: ${{ inputs.aws_region }}

    - name: Generate ZIP file name and S3 key
      id: set-zip-and-s3
      shell: bash
      run: |
        runtime_sanitized=$(echo "${{ inputs.python_runtime }}" | tr -d '.')
        zip_file="${{ inputs.app_name }}-${runtime_sanitized}.zip"
        s3_prefix="applayers/${{ inputs.app_name }}-${runtime_sanitized}"
        s3_key="${s3_prefix}.zip"

        echo "üîπ Python runtime: ${{ inputs.python_runtime }}"
        echo "üîπ Sanitized runtime: $runtime_sanitized"
        echo "üîπ Generated ZIP: $zip_file"
        echo "üîπ S3 prefix: $s3_prefix"
        echo "üîπ S3 key: $s3_key"

        echo "ZIP_FILE_NAME=$zip_file" >> $GITHUB_ENV
        echo "S3_PREFIX=$s3_prefix" >> $GITHUB_ENV
        echo "S3_KEY=$s3_key" >> $GITHUB_ENV

        echo "zip_file_name=$zip_file" >> $GITHUB_OUTPUT
        echo "s3_artifact_key=$s3_key" >> $GITHUB_OUTPUT

    - name: Compute current requirements hash
      id: compute-hash
      shell: bash
      run: |
        echo "üîπ Computing hash for: ${{ inputs.requirements_path }}"
        if [ ! -f "${{ inputs.requirements_path }}" ]; then
          echo "‚ùå Error: requirements.txt not found at path '${{ inputs.requirements_path }}'"
          exit 1
        fi
        current_hash=$(sha256sum "${{ inputs.requirements_path }}" | cut -d ' ' -f1)
        echo "üîπ Current hash: $current_hash"
        echo "CURRENT_HASH=$current_hash" >> $GITHUB_ENV

    - name: Fetch previous hash from S3 (if any)
      id: fetch-prev-hash
      continue-on-error: true
      shell: bash
      run: |
        echo "üîπ Checking for previous hash at s3://${{ inputs.s3_layer_bucket_name }}/${S3_PREFIX}.hash"
        aws s3 cp "s3://${{ inputs.s3_layer_bucket_name }}/${S3_PREFIX}.hash" prev.hash && echo "‚úÖ Previous hash downloaded" || echo "‚ö†Ô∏è No previous hash found (first run or missing file)"
        if [ -f prev.hash ]; then
          echo "PREV_HASH=$(cat prev.hash)" >> $GITHUB_ENV
          echo "üîπ Previous hash: $(cat prev.hash)"
        else
          echo "PREV_HASH=none" >> $GITHUB_ENV
          echo "üîπ Setting PREV_HASH=none"
        fi

    - name: Determine if rebuild is needed
      id: check-hash
      shell: bash
      run: |
        echo "üîπ Comparing hashes..."
        echo "Previous hash: $PREV_HASH"
        echo "Current hash:  $CURRENT_HASH"

        if [ "$CURRENT_HASH" != "$PREV_HASH" ]; then
          echo "‚úÖ Requirements changed ‚Äî will rebuild layer."
          echo "REQUIREMENTS_CHANGED=true" >> $GITHUB_ENV
        else
          echo "üü° Requirements unchanged ‚Äî skipping rebuild."
          echo "REQUIREMENTS_CHANGED=false" >> $GITHUB_ENV
        fi

    - name: Prepare build directory
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        echo "üîπ Preparing build directory..."
        rm -rf layer filtered.txt
        mkdir -p layer/python
        echo "üîπ Filtering out architecture-dependent dependencies..."
        grep -v -i "^pynacl" "${{ inputs.requirements_path }}" > filtered.txt
        echo "üîπ Filtered requirements:"
        cat filtered.txt

    - name: Install dependencies in Docker
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        echo "üîπ Installing dependencies using Python ${{ inputs.python_runtime }}..."
        docker run --rm \
          -v "$PWD":/app -w /app \
          --user $(id -u):$(id -g) \
          python:${{ inputs.python_runtime }}-slim \
          bash -c "pip install -r filtered.txt -t layer/python && echo '‚úÖ pip install completed successfully'"
        echo "üîπ Installed dependencies:"
        ls -1 layer/python | head -20 || echo "‚ö†Ô∏è No packages found in layer/python"

    - name: Zip dependencies
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        echo "üîπ Zipping dependencies into $ZIP_FILE_NAME..."
        cd layer && zip -r "../$ZIP_FILE_NAME" python && cd ..
        echo "‚úÖ Created ZIP: $(du -h "$ZIP_FILE_NAME")"

        - name: Upload ZIP and hash to S3
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        echo "üîπ Uploading layer ZIP to S3..."
        if [ ! -f "$ZIP_FILE_NAME" ]; then
          echo "‚ùå ZIP file not found: $ZIP_FILE_NAME"
          exit 1
        fi

        ZIP_S3_URI="s3://${{ inputs.s3_layer_bucket_name }}/$S3_KEY"
        aws s3 cp "$ZIP_FILE_NAME" "$ZIP_S3_URI" --no-progress \
          && echo "‚úÖ ZIP uploaded successfully to $ZIP_S3_URI" \
          || (echo "‚ùå ZIP upload failed to $ZIP_S3_URI" && exit 1)

        echo "üîπ Uploading requirements hash to S3..."
        HASH_S3_URI="s3://${{ inputs.s3_layer_bucket_name }}/${S3_PREFIX}.hash"
        echo "$CURRENT_HASH" | aws s3 cp - "$HASH_S3_URI" --no-progress \
          && echo "‚úÖ Hash uploaded successfully to $HASH_S3_URI" \
          || (echo "‚ùå Hash upload failed to $HASH_S3_URI" && exit 1)

        echo "üîπ Upload complete."
