name: 'Build Lambda Layer Zip and Upload to S3'
description: 'Builds Lambda layer ZIP from requirements.txt, hashes the artifact, and uploads to S3 only if the artifact hash differs.'

inputs:
  requirements_path:
    description: 'Path to requirements.txt file'
    required: true
  app_name:
    description: 'Name of application (used in .zip name)'
    required: true
  python_runtime:
    description: 'Python runtime version Layers are built for (e.g., 3.11)'
    required: true
  s3_layer_bucket_name:
    description: 'Name of the S3 bucket to upload the ZIP file to'
    required: false
    default: 'lambda.layer.python3'
  aws_region:
    description: 'AWS region for S3 bucket'
    required: false
    default: 'us-east-2'
  aws_role_arn:
    description: 'ARN of AWS IAM role to assume for S3 access'
    required: true

outputs:
  zip_file_name:
    description: 'Final ZIP file name including .zip extension'
    value: ${{ steps.set-zip-and-s3.outputs.zip_file_name }}
  s3_artifact_key:
    description: 'Full S3 key for the uploaded ZIP artifact'
    value: ${{ steps.set-zip-and-s3.outputs.s3_artifact_key }}
  s3_artifact_hash_key:
    description: "Full S3 key for the uploaded artifact's hash file"
    value: ${{ steps.set-zip-and-s3.outputs.s3_artifact_hash_key }}

runs:
  using: 'composite'
  steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ inputs.aws_role_arn }}
        aws-region: ${{ inputs.aws_region }}

    - name: Generate ZIP file name and S3 key
      id: set-zip-and-s3
      shell: bash
      run: |
        runtime_sanitized=$(echo "${{ inputs.python_runtime }}" | tr -d '.')
        zip_file="${{ inputs.app_name }}-${runtime_sanitized}.zip"
        s3_prefix="applayers/${{ inputs.app_name }}-${runtime_sanitized}"
        s3_key="${s3_prefix}.zip"
        s3_hash_key="${s3_prefix}.hash"

        echo "ðŸ”¹ Python runtime: ${{ inputs.python_runtime }}"
        echo "ðŸ”¹ Sanitized runtime: $runtime_sanitized"
        echo "ðŸ”¹ Generated ZIP: $zip_file"
        echo "ðŸ”¹ S3 prefix: $s3_prefix"
        echo "ðŸ”¹ S3 key: $s3_key"

        echo "ZIP_FILE_NAME=$zip_file" >> $GITHUB_ENV
        echo "S3_PREFIX=$s3_prefix" >> $GITHUB_ENV
        echo "S3_KEY=$s3_key" >> $GITHUB_ENV
        echo "S3_HASH_KEY=$s3_hash_key" >> $GITHUB_ENV

        echo "zip_file_name=$zip_file" >> $GITHUB_OUTPUT
        echo "s3_artifact_key=$s3_key" >> $GITHUB_OUTPUT
        echo "s3_artifact_hash_key=$s3_hash_key" >> $GITHUB_OUTPUT

        echo "s3_artifact_key: $s3_key"
        echo "s3_artifact_hash_key: $s3_hash_key"

    - name: Prepare build directory
      shell: bash
      run: |
        echo "ðŸ”¹ Preparing build directory..."
        rm -rf layer filtered.txt
        mkdir -p layer/python
        echo "ðŸ”¹ Filtering out architecture-dependent dependencies..."
        grep -v -i "^pynacl" "${{ inputs.requirements_path }}" > filtered.txt
        echo "ðŸ”¹ Filtered requirements:"
        cat filtered.txt

    - name: Install dependencies in Docker
      shell: bash
      run: |
        echo "ðŸ”¹ Installing dependencies for Python ${{ inputs.python_runtime }}..."
        docker run --rm \
          -v "$PWD":/app -w /app \
          --user $(id -u):$(id -g) \
          python:${{ inputs.python_runtime }}-slim \
          bash -c "pip install -r filtered.txt -t layer/python && echo 'âœ… pip install completed successfully'"
        echo "ðŸ”¹ Installed dependencies:"
        ls -1 layer/python | head -20 || echo "âš ï¸ No packages found in layer/python"

    - name: Zip dependencies
      shell: bash
      run: |
        echo "ðŸ”¹ Silently zipping dependencies into $ZIP_FILE_NAME..."
        cd layer && zip -r "../$ZIP_FILE_NAME" python > /dev/null && cd ..
        echo "âœ… Created ZIP: $(du -h "$ZIP_FILE_NAME")"

    - name: Compute artifact hash
      id: compute-zip-hash
      shell: bash
      run: |
        echo "ðŸ”¹ Computing base64-encoded SHA256 for $ZIP_FILE_NAME..."
        artifact_hash=$(sha256sum "$ZIP_FILE_NAME" | cut -d ' ' -f1 | xxd -r -p | base64 | tr -d '\n')
        echo "ðŸ”¹ Artifact hash: $artifact_hash"
        echo "ARTIFACT_HASH=$artifact_hash" >> $GITHUB_ENV
        echo "artifact_hash=$artifact_hash" >> $GITHUB_OUTPUT

    - name: Fetch previous artifact hash from S3 (if any)
      id: fetch-prev-hash
      continue-on-error: true
      shell: bash
      run: |
        HASH_S3_URI="s3://${{ inputs.s3_layer_bucket_name }}/${S3_HASH_KEY}"
        echo "ðŸ”¹ Checking for previous hash at $HASH_S3_URI"
        aws s3 cp "$HASH_S3_URI" prev.hash && echo "âœ… Previous hash downloaded" || echo "âš ï¸ No previous hash found (first run or missing file)"
        if [ -f prev.hash ]; then
          prev_hash=$(cat prev.hash | tr -d '\n\r')
          echo "PREV_HASH=$prev_hash" >> $GITHUB_ENV
          echo "ðŸ”¹ Previous hash: $prev_hash"
        else
          echo "PREV_HASH=none" >> $GITHUB_ENV
          echo "ðŸ”¹ Setting PREV_HASH=none"
        fi

    - name: Compare artifact hashes
      id: check-hash
      shell: bash
      run: |
        echo "ðŸ”¹ Comparing hashes..."
        echo "Previous hash: $PREV_HASH"
        echo "Current hash:  $ARTIFACT_HASH"

        if [ "$ARTIFACT_HASH" != "$PREV_HASH" ]; then
          echo "âœ… Artifact changed â€” will upload new version."
          echo "ARTIFACT_CHANGED=true" >> $GITHUB_ENV
        else
          echo "ðŸŸ¡ Artifact unchanged â€” skipping upload."
          echo "ARTIFACT_CHANGED=false" >> $GITHUB_ENV
        fi

    - name: Upload new artifact and hash to S3
      if: env.ARTIFACT_CHANGED == 'true'
      shell: bash
      run: |
        ZIP_S3_URI="s3://${{ inputs.s3_layer_bucket_name }}/$S3_KEY"
        HASH_S3_URI="s3://${{ inputs.s3_layer_bucket_name }}/${S3_HASH_KEY}"

        echo "ðŸ”¹ Uploading ZIP to $ZIP_S3_URI..."
        aws s3 cp "$ZIP_FILE_NAME" "$ZIP_S3_URI" --no-progress \
          && echo "âœ… ZIP uploaded successfully."

        echo "ðŸ”¹ Uploading hash to $HASH_S3_URI..."
        echo -n "$ARTIFACT_HASH" | aws s3 cp - "$HASH_S3_URI" --no-progress \
          && echo "âœ… Hash uploaded successfully."
