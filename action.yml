name: 'Build Lambda Layer Zip and Upload to S3'
description: 'Installs dependencies from requirements.txt, zips for Lambda Layer, and uploads to S3.'

inputs:
  requirements_path:
    description: 'Path to requirements.txt file'
    required: true
  app_name:
    description: 'Name of application (used in .zip name)'
    required: true
  python_runtime:
    description: 'Python runtime version Layers are built for (e.g., 3.11)'
    required: true
  s3_layer_bucket_name:
    description: 'Name of the S3 bucket to upload the ZIP file to'
    required: false
    default: 'lambda.layer.python3'
  aws_region:
    description: 'AWS region for S3 bucket'
    required: false
    default: 'us-east-2'
  aws_role_arn:
    description: 'ARN of AWS IAM role to assume for S3 access'
    required: true

outputs:
  zip_file_name:
    description: 'Final ZIP file name including .zip extension'
    value: ${{ steps.set-outputs.outputs.zip_file_name }}
  s3_artifact_key:
    description: 'Full S3 key for the uploaded ZIP artifact'
    value: ${{ steps.set-outputs.outputs.s3_artifact_key }}

runs:
  using: 'composite'
  steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set outputs for ZIP file name and S3 key
      id: set-zip-and-s3
      shell: bash
      run: |
        # Generate ZIP file name
        runtime_sanitized=$(echo "${{ inputs.python_runtime }}" | tr -d '.')
        zip_file="${{ inputs.app_name }}-${runtime_sanitized}.zip"
        echo "ZIP_FILE_NAME=$zip_file" >> $GITHUB_ENV

        # Generate S3 key from ZIP file name
        s3_key="applayers/$zip_file"
        echo "S3_KEY=$s3_key" >> $GITHUB_ENV

        echo "zip_file_name=${{ env.ZIP_FILE_NAME }}" >> $GITHUB_OUTPUT
        echo "s3_artifact_key=${{ env.S3_KEY }}" >> $GITHUB_OUTPUT

    - name: Check if requirements.txt changed
      id: check-requirements
      run: |
        CHANGED=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep '^requirements.txt' || true)
        if [ -n "$CHANGED" ]; then
          echo "REQUIREMENTS_CHANGED=true" >> $GITHUB_ENV
        else
          echo "REQUIREMENTS_CHANGED=false" >> $GITHUB_ENV
        fi

    # Remaining steps only run if requirements.txt changed

    - name: Prepare build directory
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        rm -rf layer filtered.txt
        mkdir -p layer/python
        # Filter out architecture-dependent dependencies like pynacl
        grep -v -i "^pynacl" "${{ inputs.requirements_path }}" > filtered.txt

    - name: Install pure-Python dependencies inside Lambda runtime container
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        docker run --rm \
          -v "$PWD":/app -w /app \
          --user $(id -u):$(id -g) \
          python:${{ inputs.python_runtime }}-slim \
          pip install -r filtered.txt -t layer/python

    - name: Zip dependencies
      if: env.REQUIREMENTS_CHANGED == 'true'
      id: zip
      shell: bash
      run: |
        runtime_sanitized=$(echo "${{ inputs.python_runtime }}" | tr -d '.')
        zip_file="${{ inputs.app_name }}-${runtime_sanitized}.zip"
        cd layer && zip -r "../$zip_file" python && cd ..
        echo "ZIP_FILE_NAME=$zip_file" >> $GITHUB_ENV

    - name: Configure AWS credentials (OIDC + role assumption)
      if: env.REQUIREMENTS_CHANGED == 'true'
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ inputs.aws_role_arn }}
        aws-region: ${{ inputs.aws_region }}

    - name: Upload to S3
      if: env.REQUIREMENTS_CHANGED == 'true'
      id: upload
      shell: bash
      run: |
        s3_key="applayers/${{ env.ZIP_FILE_NAME }}"
        aws s3 cp "${{ env.ZIP_FILE_NAME }}" "s3://${{ inputs.s3_layer_bucket_name }}/$s3_key"
        echo "S3_KEY=$s3_key" >> $GITHUB_ENV
