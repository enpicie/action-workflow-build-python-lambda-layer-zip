name: 'Build Lambda Layer Zip and Upload to S3'
description: 'Installs dependencies from requirements.txt, zips for Lambda Layer, and uploads to S3 if requirements changed.'

inputs:
  requirements_path:
    description: 'Path to requirements.txt file'
    required: true
  app_name:
    description: 'Name of application (used in .zip name)'
    required: true
  python_runtime:
    description: 'Python runtime version Layers are built for (e.g., 3.11)'
    required: true
  s3_layer_bucket_name:
    description: 'Name of the S3 bucket to upload the ZIP file to'
    required: false
    default: 'lambda.layer.python3'
  aws_region:
    description: 'AWS region for S3 bucket'
    required: false
    default: 'us-east-2'
  aws_role_arn:
    description: 'ARN of AWS IAM role to assume for S3 access'
    required: true

outputs:
  zip_file_name:
    description: 'Final ZIP file name including .zip extension'
    value: ${{ steps.set-zip-and-s3.outputs.zip_file_name }}
  s3_artifact_key:
    description: 'Full S3 key for the uploaded ZIP artifact'
    value: ${{ steps.set-zip-and-s3.outputs.s3_artifact_key }}

runs:
  using: 'composite'
  steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Configure AWS credentials (OIDC + role assumption)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ inputs.aws_role_arn }}
        aws-region: ${{ inputs.aws_region }}

    - name: Generate ZIP file name and S3 key
      id: set-zip-and-s3
      shell: bash
      run: |
        runtime_sanitized=$(echo "${{ inputs.python_runtime }}" | tr -d '.')
        zip_file="${{ inputs.app_name }}-${runtime_sanitized}.zip"
        s3_prefix="applayers/${{ inputs.app_name }}-${runtime_sanitized}"
        s3_key="${s3_prefix}.zip"

        echo "ğŸ”¹ Python runtime: ${{ inputs.python_runtime }}"
        echo "ğŸ”¹ Sanitized runtime: $runtime_sanitized"
        echo "ğŸ”¹ Generated ZIP: $zip_file"
        echo "ğŸ”¹ S3 prefix: $s3_prefix"
        echo "ğŸ”¹ S3 key: $s3_key"

        echo "ZIP_FILE_NAME=$zip_file" >> $GITHUB_ENV
        echo "S3_PREFIX=$s3_prefix" >> $GITHUB_ENV
        echo "S3_KEY=$s3_key" >> $GITHUB_ENV

        echo "zip_file_name=$zip_file" >> $GITHUB_OUTPUT
        echo "s3_artifact_key=$s3_key" >> $GITHUB_OUTPUT

    - name: Compute current requirements hash
      id: compute-hash
      shell: bash
      run: |
        echo "ğŸ”¹ Computing hash for: ${{ inputs.requirements_path }}"
        if [ ! -f "${{ inputs.requirements_path }}" ]; then
          echo "âŒ Error: requirements.txt not found at path '${{ inputs.requirements_path }}'"
          exit 1
        fi
        current_hash=$(sha256sum "${{ inputs.requirements_path }}" | cut -d ' ' -f1)
        echo "ğŸ”¹ Current hash: $current_hash"
        echo "CURRENT_HASH=$current_hash" >> $GITHUB_ENV

    - name: Fetch previous hash from S3 (if any)
      id: fetch-prev-hash
      continue-on-error: true
      shell: bash
      run: |
        echo "ğŸ”¹ Checking for previous hash at s3://${{ inputs.s3_layer_bucket_name }}/${S3_PREFIX}.hash"
        aws s3 cp "s3://${{ inputs.s3_layer_bucket_name }}/${S3_PREFIX}.hash" prev.hash && echo "âœ… Previous hash downloaded" || echo "âš ï¸ No previous hash found (first run or missing file)"
        if [ -f prev.hash ]; then
          echo "PREV_HASH=$(cat prev.hash)" >> $GITHUB_ENV
          echo "ğŸ”¹ Previous hash: $(cat prev.hash)"
        else
          echo "PREV_HASH=none" >> $GITHUB_ENV
          echo "ğŸ”¹ Setting PREV_HASH=none"
        fi

    - name: Determine if rebuild is needed
      id: check-hash
      shell: bash
      run: |
        echo "ğŸ”¹ Comparing hashes..."
        echo "Previous hash: $PREV_HASH"
        echo "Current hash:  $CURRENT_HASH"

        if [ "$CURRENT_HASH" != "$PREV_HASH" ]; then
          echo "âœ… Requirements changed â€” will rebuild layer."
          echo "REQUIREMENTS_CHANGED=true" >> $GITHUB_ENV
        else
          echo "ğŸŸ¡ Requirements unchanged â€” skipping rebuild."
          echo "REQUIREMENTS_CHANGED=false" >> $GITHUB_ENV
        fi

    - name: Prepare build directory
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        echo "ğŸ”¹ Preparing build directory..."
        rm -rf layer filtered.txt
        mkdir -p layer/python
        echo "ğŸ”¹ Filtering out architecture-dependent dependencies..."
        grep -v -i "^pynacl" "${{ inputs.requirements_path }}" > filtered.txt
        echo "ğŸ”¹ Filtered requirements:"
        cat filtered.txt

    - name: Install dependencies in Docker
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        echo "ğŸ”¹ Installing dependencies using Python ${{ inputs.python_runtime }}..."
        docker run --rm \
          -v "$PWD":/app -w /app \
          --user $(id -u):$(id -g) \
          python:${{ inputs.python_runtime }}-slim \
          bash -c "pip install -r filtered.txt -t layer/python && echo 'âœ… pip install completed successfully'"
        echo "ğŸ”¹ Installed dependencies:"
        ls -1 layer/python | head -20 || echo "âš ï¸ No packages found in layer/python"

    - name: Zip dependencies
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        echo "ğŸ”¹ Zipping dependencies into $ZIP_FILE_NAME..."
        cd layer && zip -r "../$ZIP_FILE_NAME" python && cd ..
        echo "âœ… Created ZIP: $(du -h "$ZIP_FILE_NAME")"

    - name: Upload ZIP and hash to S3
      if: env.REQUIREMENTS_CHANGED == 'true'
      shell: bash
      run: |
        echo "ğŸ”¹ Uploading layer ZIP to S3..."
        if [ ! -f "$ZIP_FILE_NAME" ]; then
          echo "âŒ ZIP file not found: $ZIP_FILE_NAME"
          exit 1
        fi

        aws s3 cp "$ZIP_FILE_NAME" "s3://${{ inputs.s3_layer_bucket_name }}/$S3_KEY" --no-progress && echo "âœ… ZIP uploaded successfully" || (echo "âŒ ZIP upload failed" && exit 1)

        echo "ğŸ”¹ Uploading hash to S3..."
        echo "$CURRENT_HASH" | aws s3 cp - "s3://${{ inputs.s3_layer_bucket_name }}/${S3_PREFIX}.hash" --no-progress && echo "âœ… Hash uploaded successfully" || (echo "âŒ Hash upload failed" && exit 1)

        echo "ğŸ”¹ Upload complete."
